# Dialyzer, ETC, and Gradualizer 2

```elixir
Mix.install([
  {:csv, "~> 2.4"},
  {:httpotion, "~> 3.1.0"},
  {:kino_vega_lite, "~> 0.1.1"}
])
```

## Let's get the test data

```elixir
tsv_url =
  "https://gist.githubusercontent.com/erszcz/4d43a77464c87a514e71eecf2811af63/raw/bf8d18cfd236e82bba794c169b57f1f284475ddd/check.2022-07-13_170833.tsv"

response = HTTPotion.get(tsv_url)
```

```elixir
tab = 0x09

{:ok, stream} =
  response.body
  |> StringIO.open()

tsv =
  stream
  |> IO.binstream(:line)
  |> CSV.decode!(separator: tab)
  |> Enum.into([])
  |> Enum.drop(1)
```

```elixir
headers = [
  :type,
  :dialyzer,
  :etc,
  :gradualizer,
  :dialyzer_seconds,
  :etc_seconds,
  :gradualizer_seconds,
  :file
]

# series by header
by_header =
  tsv
  |> Enum.zip()
  |> Enum.map(&Tuple.to_list/1)

by_header = Enum.zip(headers, by_header) |> Enum.into(%{})
```

```elixir
by_test_type = tsv |> Enum.group_by(&List.first/1)

tool_to_index = %{
  dialyzer: 1,
  etc: 2,
  gradualizer: 3
}

extract_tool = fn row, tool ->
  case Enum.at(row, tool_to_index[tool]) do
    "ok" -> [tool |> to_string() |> String.capitalize()]
    _ -> []
  end
end

map_test_type_series_to_tools = fn series ->
  series
  |> Enum.flat_map(fn row ->
    [
      ["All tests"],
      extract_tool.(row, :dialyzer),
      extract_tool.(row, :etc),
      extract_tool.(row, :gradualizer)
    ]
    |> Enum.concat()
  end)
end

by_test_type = %{
  "known_problems_should_fail" =>
    map_test_type_series_to_tools.(by_test_type["known_problems_should_fail"]),
  "known_problems_should_pass" =>
    map_test_type_series_to_tools.(by_test_type["known_problems_should_pass"]),
  "should_fail" => map_test_type_series_to_tools.(by_test_type["should_fail"]),
  "should_pass" => map_test_type_series_to_tools.(by_test_type["should_pass"])
}
```

```elixir
# Sanity check!
[n_should_pass, n_known_problems_should_pass, n_should_fail, n_known_problems_should_fail] = [
  by_test_type["should_pass"] |> Enum.filter(fn e -> e == "All tests" end) |> length,
  by_test_type["known_problems_should_pass"]
  |> Enum.filter(fn e -> e == "All tests" end)
  |> length,
  by_test_type["should_fail"] |> Enum.filter(fn e -> e == "All tests" end) |> length,
  by_test_type["known_problems_should_fail"]
  |> Enum.filter(fn e -> e == "All tests" end)
  |> length
]

[103, 16, 86, 11] = [
  n_should_pass,
  n_known_problems_should_pass,
  n_should_fail,
  n_known_problems_should_fail
]
```

## Analysis and comparison

### Tests that should pass

This chart depicts the number of tests which should pass, i.e. should type check. After all, **we do not want our type checkers to raise warnings about valid code.**

Given we're considering code that's assumed to be valid, none of the type checkers should report warnings here. Cross-checking these tests with different type checkers allows to find bugs in tests or the type checkers themselves.

Dialyzer reports only a few errors. Gradualizer, as expected, reports none. ETC fares quite poorly, passing only 1/3 of the tests, which suggests it might not cover the complete Erlang syntax.

Higher is better.

```elixir
{should_pass_xs, should_pass_ys} =
  by_test_type["should_pass"]
  |> Enum.group_by(fn e -> e end)
  |> Enum.map(fn {type, v} -> {type, length(v)} end)
  |> Enum.unzip()

should_pass = %{
  "Tool" => should_pass_xs,
  "Tests passed" => should_pass_ys
}
```

<!-- livebook:{"attrs":{"chart_title":null,"height":300,"layers":[{"chart_type":"bar","color_field":"Tool","color_field_aggregate":null,"color_field_type":null,"data_variable":"should_pass","x_field":"Tool","x_field_aggregate":null,"x_field_type":null,"y_field":"Tests passed","y_field_aggregate":null,"y_field_type":"quantitative"}],"vl_alias":"Elixir.VegaLite","width":300},"kind":"Elixir.KinoVegaLite.ChartCell","livebook_object":"smart_cell"} -->

```elixir
VegaLite.new(width: 300, height: 300)
|> VegaLite.data_from_values(should_pass, only: ["Tool", "Tests passed"])
|> VegaLite.mark(:bar)
|> VegaLite.encode_field(:x, "Tool")
|> VegaLite.encode_field(:y, "Tests passed", type: :quantitative)
|> VegaLite.encode_field(:color, "Tool")
```

### Known problems: tests that should pass, but do not

This chart depicts the number of tests which should pass, i.e. should type check, yet raise Gradualizer errors. In other words, __these are the false positives - invalid or misleading reports about non-issues.__

Dialyzer reports only a single false positive and is a clear winner here! This confirms the slogan that _Dialyzer is never wrong_.
ETC reports some of the errors, but not all of them.
Gradualizer, as expected, reports errors for all of the tests.

Lower is better.

```elixir
{known_problems_should_pass_xs, known_problems_should_pass_ys} =
  by_test_type["known_problems_should_pass"]
  |> Enum.group_by(fn e -> e end)
  |> Enum.map(fn {type, v} -> {type, n_known_problems_should_pass - length(v)} end)
  |> Enum.unzip()

known_problems_should_pass = %{
  "Tool" => known_problems_should_pass_xs ++ ["Gradualizer"],
  "Errors detected" =>
    [n_known_problems_should_pass] ++
      Enum.drop(known_problems_should_pass_ys, 1) ++ [n_known_problems_should_pass]
}
```

<!-- livebook:{"attrs":{"chart_title":null,"height":300,"layers":[{"chart_type":"bar","color_field":"Tool","color_field_aggregate":null,"color_field_type":null,"data_variable":"known_problems_should_pass","x_field":"Tool","x_field_aggregate":null,"x_field_type":null,"y_field":"Errors detected","y_field_aggregate":null,"y_field_type":"quantitative"}],"vl_alias":"Elixir.VegaLite","width":300},"kind":"Elixir.KinoVegaLite.ChartCell","livebook_object":"smart_cell"} -->

```elixir
VegaLite.new(width: 300, height: 300)
|> VegaLite.data_from_values(known_problems_should_pass, only: ["Tool", "Errors detected"])
|> VegaLite.mark(:bar)
|> VegaLite.encode_field(:x, "Tool")
|> VegaLite.encode_field(:y, "Errors detected", type: :quantitative)
|> VegaLite.encode_field(:color, "Tool")
```

### Tests which should fail

This chart depicts the number of tests which should fail, i.e. should not type check. **These tests check that the warnings we want to see in our buggy code are actually generated.**

Dialyzer seems to be somewhat permissive. ETC reports the majority of errors. Gradualizer properly reports all the errors.

Higher is better.

```elixir
{should_fail_xs, should_fail_ys} =
  by_test_type["should_fail"]
  |> Enum.group_by(fn e -> e end)
  |> Enum.map(fn {type, v} -> {type, n_should_fail - length(v)} end)
  |> Enum.unzip()

should_fail = %{
  "Tool" => should_fail_xs ++ ["Gradualizer"],
  "Errors detected" => [n_should_fail] ++ Enum.drop(should_fail_ys, 1) ++ [n_should_fail]
}
```

<!-- livebook:{"attrs":{"chart_title":null,"height":300,"layers":[{"chart_type":"bar","color_field":"Tool","color_field_aggregate":null,"color_field_type":null,"data_variable":"should_fail","x_field":"Tool","x_field_aggregate":null,"x_field_type":null,"y_field":"Errors detected","y_field_aggregate":null,"y_field_type":"quantitative"}],"vl_alias":"Elixir.VegaLite","width":300},"kind":"Elixir.KinoVegaLite.ChartCell","livebook_object":"smart_cell"} -->

```elixir
VegaLite.new(width: 300, height: 300)
|> VegaLite.data_from_values(should_fail, only: ["Tool", "Errors detected"])
|> VegaLite.mark(:bar)
|> VegaLite.encode_field(:x, "Tool")
|> VegaLite.encode_field(:y, "Errors detected", type: :quantitative)
|> VegaLite.encode_field(:color, "Tool")
```

### Known problems: tests that should fail, but do not

This chart depicts the number of tests which should fail, i.e. should not type check, but are known to type check with Gradualizer. In other words, **these are the errors that considered type checkers cannot find.** We have to rely on tests, code review, or other techniques to find them.

Dialyzer detects some of the errors in these examples, ETC seems to detect even more. Gradualizer doesn't detect any of them, but the examples are crafted against this type checker, so it's expected.

Higher is better.

```elixir
{known_problems_should_fail_xs, known_problems_should_fail_ys} =
  by_test_type["known_problems_should_fail"]
  |> Enum.group_by(fn e -> e end)
  |> Enum.map(fn {type, v} -> {type, n_known_problems_should_fail - length(v)} end)
  |> Enum.unzip()

known_problems_should_fail = %{
  "Tool" => known_problems_should_fail_xs,
  "Errors detected" =>
    [n_known_problems_should_fail] ++ Enum.drop(known_problems_should_fail_ys, 1)
}
```

<!-- livebook:{"attrs":{"chart_title":null,"height":300,"layers":[{"chart_type":"bar","color_field":"Tool","color_field_aggregate":null,"color_field_type":null,"data_variable":"known_problems_should_fail","x_field":"Tool","x_field_aggregate":null,"x_field_type":null,"y_field":"Errors detected","y_field_aggregate":null,"y_field_type":"quantitative"}],"vl_alias":"Elixir.VegaLite","width":300},"kind":"Elixir.KinoVegaLite.ChartCell","livebook_object":"smart_cell"} -->

```elixir
VegaLite.new(width: 300, height: 300)
|> VegaLite.data_from_values(known_problems_should_fail, only: ["Tool", "Errors detected"])
|> VegaLite.mark(:bar)
|> VegaLite.encode_field(:x, "Tool")
|> VegaLite.encode_field(:y, "Errors detected", type: :quantitative)
|> VegaLite.encode_field(:color, "Tool")
```

## Some examples

#### should_pass/andalso_any.erl

Described at https://github.com/josefs/Gradualizer/pull/429#discussion_r920465166.
Seems to be a soundness error in Gradualizer!

<!-- livebook:{"break_markdown":true} -->

#### should_pass/binary_exhaustiveness_checking.erl

Dialyzer warns about an unexported function.
Gradualizer type checks functions no matter if they're exported or not.
Dialyzer warning goes away after we export `l/1`.

Fixed for Dialyzer with https://github.com/josefs/Gradualizer/pull/430.

<!-- livebook:{"break_markdown":true} -->

#### should_pass/flow.erl

Dialyzer sees no other local call sites than `bar(apa)`,
therefore infers the argument type of `bar/1` to be just `apa`,
which in turn means that the second clause of `bar/1` is redudant.
This leads to a valid warning.

Adding `-export([bar/1])` at the top makes Dialyzer accept the code.

Gradualizer does not warn either with or without the extra `export` attribute.

Fixed for Dialyzer with https://github.com/josefs/Gradualizer/pull/431.

<!-- livebook:{"break_markdown":true} -->

#### should_pass/iodata.erl

Dialyzer detects an improper list creation, which is not an error for Gradualizer (but maybe it should?) - passing `--infer` to Gradualizer doesn't change the outcome.

<!-- livebook:{"break_markdown":true} -->

#### should_pass/named_fun_infer_pass.erl

Dialyzer infers that 0 in `F(Atoms, 0)` is not a list of integers.
Gradualizer does not.

<!-- livebook:{"break_markdown":true} -->

#### should_pass/named_fun_pass.erl

Dialyzer fails due to arity mismatch.
Gradualizer does so only with `--infer`. Dialyzer is inferring more aggressively.

<!-- livebook:{"break_markdown":true} -->

#### should_pass/negate_none.erl

Dialyzer returns "no local return" from `foo/0`.
Gradualizer is silent.

<!-- livebook:{"break_markdown":true} -->

#### should_pass/records.erl

Dialyzer reported unexported local functions which would never be called.
Gradualizer did not, but the Erlang compiler would, so it's not a big deal.

<!-- livebook:{"break_markdown":true} -->

#### should_pass/return_fun.erl

One of the few cases in `should_pass` tests where Dialyzer actually detects errors,
whereas Gradualizer does not.

```erlang
-spec return_fun_no_spec() -> integer().
return_fun_no_spec() -> fun no_spec/0.

no_spec() -> ok.
```

Dialyzer:

```
return_fun.erl:28:2: Invalid type specification for function return_fun:return_fun_no_spec/0.
The success typing is
          () -> fun(() -> 'ok')
```

ETC:

```
test/should_pass/return_fun.erl: error in parse transform
```

Gradualizer: no error!

Let's remember that by default Gradualizer doesn't infer types of functions with no specs.

Gradualizer with `--infer`:

```
return_fun.erl:29:25: The fun expression is expected to have type integer()
but it has type fun(() -> any())
```

Dialyzer seems to infer more types by default.
However, if we ask Gradualizer to try a bit harder, it's even with Dialyzer on this one.
The file is too complex for ETC to process - it crashes :(

<!-- livebook:{"break_markdown":true} -->

#### should_pass/scope.erl

Another one of the few cases in `should_pass` tests where Dialyzer detects errors,
but Gradualizer does not.

```
f(X) ->
    case g(X) of
        true -> A = 5,
                B = 7;
        false -> B = 6
    end,
    B.

g(_X) ->
    true.
```

Dialyzer:

```
scope.erl:9:9: The pattern 'false' can never match the type 'true'
```

ETC: ok

Gradualizer: ok

Another example showing that Dialyzer type inference is quite aggressive and quite accurate!
It knows that `g/1` can never return anything else than `true`,
so the latter clause of the case expression enclosing the `g(X)` call is redundant.
In this case the entire case expression is redundant and `B` will always be 7.

It's interesting to note that Gradualizer cannot detect the error even if we modify the code as follows:

TODO: create a bug report about it!

```
-spec f(any()) -> atom().
f(X) ->
    case g(X) of
        true -> A = 5,
                B = 7;
        false -> B = 6
    end,
    B.

-spec g(any()) -> true.
g(_X) ->
    true.
```

<!-- livebook:{"break_markdown":true} -->

#### known_problems/should_pass/list_tail.erl

The only false positive raised by Dialyzer, which is known for _never being wrong_. Is it a Dialyzer bug?

```erlang
atom_tail() ->
    [ 1 | list_to_atom("banana") ].
```

Dialyzer:

```
list_tail.erl:7:5: Cons will produce an improper list since its 2nd argument is atom()
```

ETC:

```
unify failed with types [integer] :=: atom
```

Gradualizer:

```
list_tail.erl:7: The expression of type atom() is not a list type
```

Apparently, all the type checkers agree. It definitely is not a Dialyzer bug. Maybe the test should be moved from `known_problems/should_pass` to `should_fail`?

<!-- livebook:{"break_markdown":true} -->

#### known_problems/should_pass/arith_op_arg_types.erl

Gradualizer is wrong about integer type inference in presence of arithmetic operations. Dialyzer is fine with it.

<!-- livebook:{"break_markdown":true} -->

#### known_problems/should_pass/binary_exhaustiveness_checking_should_pass.erl

Gradualizer cannot tell that `<<_:24>>` is a subtype of `<<_:_*8>>`.

<!-- livebook:{"break_markdown":true} -->

#### should_fail/annotated_types_fail.erl

Gradualizer provides type annotation/assertion macros which can be used to provide extra type information by the programmer. Gradualizer correctly finds types discrepancies between specs and annotations.

Dialyzer does not understand the annotation macros and does not have enough info to find type errors. Dialyzer is more permissive.

<!-- livebook:{"break_markdown":true} -->

#### should_fail/branch.erl

Given the code:

```
-spec c(boolean()) -> integer().
c(X) ->
    X.
```

Dialyzer (with no extra flags) does not detect type mismatch. With `-Wspecdiffs` or `-Woverspecs` it reports:

```
branch.erl:5:2: Type specification branch:c
          (boolean()) -> integer() is a subtype of the success typing: branch:c
          (_) -> any()
```

The report is correct. Arguably, though, it's a bit hard to understand.

Gradualizer reports:

```
The variable is expected to have type integer() but it has type false | true
```

<!-- livebook:{"break_markdown":true} -->

#### should_fail/branch2.erl

Given the code:

```
-spec c(boolean()) -> integer().
c(true) ->
    1;
c(false) ->
    apa.
```

Dialyzer (with no options) does not detect type mismatch. With `-Wspecdiffs` it reports:

```
branch2.erl:5:2: The success typing for branch2:c/1 implies that the function might also return
          'apa' but the specification return is
          integer()
```

Which is expected.

Gradualizer by default reports:

```
The atom is expected to have type integer() but it has type apa:

    1;
c(false) ->
    apa.
    ^^^
```

<!-- livebook:{"break_markdown":true} -->

#### should_fail/case_pattern.erl

Given the code:

```
-spec f(integer(), atom()) -> ok.
f(X, Y) ->
    case Y of
        X -> ok
    end.
```

Dialyzer (with no options) cannot figure out that the pattern (matching integers) will never match an atom. With `-Wspecdiffs` a misleading warning is printed:

```
case_pattern.erl:4:2: Type specification case_pattern:f
          (integer(), atom()) -> 'ok' is a subtype of the success typing: case_pattern:f
          (_, _) -> 'ok'
```

The warning suggests that our spec is too specific, whereas in practice its explicitness enables the type checker to figure out that the case expression will never match.

Gradualizer reports:

```
The variable is expected to have type atom() but it has type integer():

f(X, Y) ->
    case Y of
        X -> ok
        ^
```

At runtime, the code fails with:

```
2> case_pattern:f(3, a).
** exception error: no case clause matching a
     in function  case_pattern:f/2 (test/should_fail/case_pattern.erl, line 6)
```

So Gradualizer detects an actual bug that Dialyzer does not.

<!-- livebook:{"break_markdown":true} -->

#### should_fail/case_pattern2.erl

Given the code:

```
-spec f(integer(), atom()) -> ok.
f(X, Y) ->
    case {X, Y} of
        {Z, Z} -> ok
    end.
```

Dialyzer (with no options) cannot figure out that the pattern will never match the expression as X and Y are of different types. With `-Wspecdiffs` it suggests the spec is too strict:

```
case_pattern2.erl:4:2: Type specification case_pattern2:f
          (integer(), atom()) -> 'ok' is a subtype of the success typing: case_pattern2:f
          (_, _) -> 'ok'
```

Gradualizer reports that:

```
The variable is expected to have type atom() but it has type integer():

f(X, Y) ->
    case {X, Y} of
        {Z, Z} -> ok
            ^
```

So Gradualizer prevents the runtime error:

```
2> case_pattern2:f(3, a).
** exception error: no case clause matching {3,a}
     in function  case_pattern2:f/2 (test/should_fail/case_pattern2.erl, line 6)
```

<!-- livebook:{"break_markdown":true} -->

#### should_fail/covariant_map_keys_fail.erl

Given the code:

```
-spec good(#{ good := A }) -> A.
good(#{ good := X }) -> X.

-spec not_good(#{good | bad := A}) -> A.
not_good(M) -> good(M). %% This call should fail

-spec kaboom() -> integer().
kaboom() -> not_good(#{ bad => 0 }).
```

Dialyzer (with no options) does not detect any errors. With `-Wspecdiffs` it reports:

```
covariant_map_keys_fail.erl:6:2: Type specification covariant_map_keys_fail:good
          (#{'good' := A}) -> A is a subtype of the success typing: covariant_map_keys_fail:good
          (#{'good' := _, _ => _}) -> any()
covariant_map_keys_fail.erl:9:2: Type specification covariant_map_keys_fail:not_good
          (#{'good' | 'bad' := A}) -> A is a supertype of the success typing: covariant_map_keys_fail:not_good
          (#{'good' := _}) -> any()
covariant_map_keys_fail.erl:12:2: The specification for covariant_map_keys_fail:kaboom/0 states that the function might also return
          integer() but the inferred return is
          none()
```

Dialyzer suggests the information we pass in `good/1` spec is redundant. It hints at an error in `not_good/1`, but is not explicit about it. It correctly detects an error in `kaboom/0`.

Gradualizer reports:

```
The variable is expected to have type #{good := A} but it has type #{bad | good := A}

-spec not_good(#{good | bad := A}) -> A.
not_good(M) -> good(M).
                    ^
```

Gradualizer does not detect the error in `kaboom/0`, but it does detect the more local error in `not_good/1`. If we fix the error in `not_good/1`, the error in `kaboom/0` will automatically be fixed, too.

However, Gradualizer, even with the `--infer` flag, does not infer the type of `#{ bad => 0 }` expression passed into `not_good/1` as an argument. This is now tracked as https://github.com/josefs/Gradualizer/issues/432.

Interestingly, if we modify the code to:

```
-spec kaboom() -> integer().
kaboom() ->
    M = #{ bad => 0 },
    not_good(M).
```

Gradualizer is able to report also this error:

```
The variable is expected to have type #{good | bad := A} but it has type #{bad => 0}

kaboom() ->
    M = #{ bad => 0 },
    not_good(M).
             ^
```

The runtime error Gradualizer protects from is:

```
2> covariant_map_keys_fail:not_good(#{bad => 0}).
** exception error: no function clause matching covariant_map_keys_fail:good(#{bad => 0}) (test/should_fail/covariant_map_keys_fail.erl, line 7)
```

<!-- livebook:{"break_markdown":true} -->

#### should_fail/cyclic_type_vars.erl

Given the code:

```
-spec foo(A) -> B when
    A :: true | B,
    B :: [A].
```

Gradualizer reports a cyclic dependency between type variables A and B. Dialyzer does not.

<!-- livebook:{"break_markdown":true} -->

#### should_fail/exhaustive.erl

Dialyzer (with no options) does not fail type checking the file. With `-Wspecdiffs` it hints at spec and implementation mismatches, but with not clear indications which are wrong.

Gradualizer assumes the specs to be right and therefore returns explicit exhaustiveness failures:

```
/Users/erszcz/work/erszcz/gradualizer/test/should_fail/exhaustive.erl:48:1: Nonexhaustive patterns: 0
```

It becomes even more apparent when we add an example of a nonexhaustive `case` expression inside a function body:

```
-spec integer_2(integer()) -> {}.
integer_2(I) ->
    case I of
        0 -> {}
    end.
```

Gradualizer reports the exact line:

```
should_fail/exhaustive.erl:53:9: Nonexhaustive patterns: -1
```

Whereas Dialyzer (with `-Wspecdiffs`) only reports a hint that our passed in type is wider than the implementation expects:

```
exhaustive.erl:50:2: Type specification exhaustive:integer_2
          (integer()) -> {} is a supertype of the success typing: exhaustive:integer_2
          (0) -> {}
```

<!-- livebook:{"break_markdown":true} -->

#### should_fail/exhaustive_float.erl

Given the code:

```
-type t() :: {int, integer()}
           | {float, float()}.

-spec ef(t()) -> ok.
ef(T) ->
    case T of
        {int, _} -> ok
    end.
```

Dialyzer (with no options) does not report any errors. With `-Wspecdiffs` it reports the following hint, which suggests that we might be missing some clauses:

```
exhaustive_float.erl:8:2: Type specification exhaustive_float:ef
          (t()) -> 'ok' is not equal to the success typing: exhaustive_float:ef
          ({'int', _}) -> 'ok'
```

Gradualizer reports a definite error:

```
should_fail/exhaustive_float.erl:11:9: Nonexhaustive patterns: {float, -1.0}
```

<!-- livebook:{"break_markdown":true} -->

#### should_fail/exhaustive_list_variants.erl

Given the code:

```
-type list_variant_t() :: {non_list, integer()}
                        | {list, [integer()]}.

-spec list_variant_omitted(list_variant_t()) -> ok.
list_variant_omitted(T) ->
    case T of
        {non_list, _} -> ok
    end.
```

Dialyzer (with no options) does not report any errors. With `-Wspecdiffs` it reports the following hint, which suggests that we might be missing some clauses:

```
exhaustive_list_variants.erl:8:2: Type specification exhaustive_list_variants:list_variant_omitted
          (list_variant_t()) -> 'ok' is not equal to the success typing: exhaustive_list_variants:list_variant_omitted
          ({'non_list', _}) -> 'ok'
```

Gradualizer reports a definite error:

```
should_fail/exhaustive_list_variants.erl:11:9: Nonexhaustive patterns: {list, []}
```

<!-- livebook:{"break_markdown":true} -->

#### known_problems/should_fail/arith_op.erl

Given the code:

```
-spec int_error(any(), float()) -> integer().
int_error(X, Y) ->
    A = X div Y,
    A.
```

Dialyzer reports a concrete error:

```
Invalid type specification for function arith_op:int_error/2. The success typing is
          (integer(), integer()) -> integer()
```

Gradualizer does not report anything.

<!-- livebook:{"break_markdown":true} -->

#### known_problems/should_fail/exhaustive_argumentwise.erl

Given the code:

```
-type t() :: ala | ola.

-spec f(t(), any()) -> ok.
f(ala, _) -> ok.
```

By default none of the typecheckers can tell that `f/2` is a partial function.

Dialyzer with `-Wspecdiffs` reports a warning that the success typing is narrower then the spec:

```
exhaustive_argumentwise.erl:7:2: Type specification exhaustive_argumentwise:f
          (t(), any()) -> 'ok' is a supertype of the success typing: exhaustive_argumentwise:f
          ('ala', _) -> 'ok'
```

## Examples from "Bidirectional Typing for Erlang" by Nithin Rajendrakumar and Annette Bieniusa

#### 1. Polymorphic list lookup

```
-spec lookup(T1, [{T1, T2}]) -> (none | T2).
lookup(_, []) -> none;
lookup(K, [{K, V}|_]) -> V;
lookup(K, [_|KVs])-> lookup(K, KVs).

find() ->
    "s" = lookup(0, [{0, 1}]).
```

By default, Dialyzer and Gradualizer do not report any errors. Dialyzer with `-Wspecdiffs` reports a misleading warning:

```
bdtfe1.erl:9:2: Type specification bdtfe1:lookup
          (T1, [{T1, T2}]) -> 'none' | T2 is a subtype of the success typing: bdtfe1:lookup
          (_, maybe_improper_list()) -> any()
```

The warning suggests that the spec is narrower than the actual implementation can handle. In practice, though, Dialyzer ignores the extra information we provide in the spec, which is crucial to identifying the bug in `find/0`.

ETC reports a unification error:

```
union-unify failed with types [char] :=: (atom|?`A)
```

ETC reports that a list of characters cannot be unified with a union of atom (`none`) and a type variable.

Gradualizer still lacks a constraint solver, so it cannot find the polymorphic type error.

<!-- livebook:{"break_markdown":true} -->

#### 2. Partial function 1/2

```
-spec foo(integer()) -> {}.
foo(1) -> true;
foo(42) -> {}.

-spec foo2(integer()) -> {}.
foo2(1) -> {};
foo2(42) -> {}.
```

In the code above the original example from the paper is copied twice, the latter copy having one type error fixed (the mismatch between `true` and `{}`) - this is to verify if our type checkers can find none, one, or both of the errors.

Dialyzer (with no options) reports nothing. With `-Wspecdiffs` it reports:

```
bdtfe3_should_fail.erl:8:2: The success typing for bdtfe3_should_fail:foo/1 implies that the function might also return
          'true' but the specification return is
          {}
bdtfe3_should_fail.erl:12:2: Type specification bdtfe3_should_fail:foo2
          (integer()) -> {} is a supertype of the success typing: bdtfe3_should_fail:foo2
          (1 | 42) -> {}
```

So Dialyzer can detect both the return type mismatch against the spec and that the function is partial.

ETC reports a unification failure of boolean and tuple:

```
unify failed with types boolean :=: tuple
```

Interestingly, if we comment out the first definition, ETC still fails on the second one with a unification failure of `tuple` and `{}`:

```
unify failed with types {} :=: tuple
```

Gradualizer with no extra options reports both a type mismatch and that the function is partial:

```
/Users/erszcz/work/vrnithinkumar/ETC/bdtfe3_should_fail.erl: The atom on line 9 at column 11 is expected to have type {} but it has type true

-spec foo(integer()) -> {}.
foo(1) -> true;
          ^^^^

/Users/erszcz/work/vrnithinkumar/ETC/bdtfe3_should_fail.erl: Nonexhaustive patterns on line 13 at column 1
Example values which are not covered:
	0
```

<!-- livebook:{"break_markdown":true} -->

#### Partial function 2/2

It's also interesting to consider the behaviour of the type checkers when we apply some changes:

```
-spec foo3(integer()) -> {}.
foo3(1) -> {};
foo3(42) -> {};
foo3(_) -> erlang:error(intentionally_partial).
```

The style above is somewhat more defensive than just "letting it crash". However, its explicitness makes it easier to understand that the function is partial on purpose, not by omission.

Dialyzer (with no options) reports nothing. With `-Wspecdiffs` it still reports that the spec is wider than the success typing:

```
bdtfe3_should_pass.erl:8:2: Type specification bdtfe3_should_pass:foo3
          (integer()) -> {} is a supertype of the success typing: bdtfe3_should_pass:foo3
          (1 | 42) -> {}
```

So with Dialyzer there's no point in using the more expressive style.

Interestingly, ETC can't unify the example:

```
unify failed with types {} :=: tuple
```

Gradualizer reports no warnings or errors. The explicit style pays off with a quick and successful type check.

<!-- livebook:{"break_markdown":true} -->

#### 3. Rank-2 polymorphism

Erlang spec syntax allows for higher-ranked polymorphism. Let's see how the type checkers cope with that.

```
-spec poly_2(fun((A) -> A)) -> {integer(), boolean()}.
poly_2(F) -> {F(42), F(false)}.
```

The above code is correct and type checks with Dialyzer, Gradualizer, and ETC. Dialyzer with `-Wspecdiffs` reports that the spec is narrower than the success typing. It's a symptom of Dialyzer ignoring the extra type information provided in the spec and assuming that the implementation is the source of truth, not the spec.

```
-spec poly_fail(fun((A) -> A), boolean(), integer()) -> {boolean(), integer()}.
poly_fail(F, B, I) -> {F(I), F(B)}.
```

The above code is not correct.

Dialyzer (with no options) does not report any errors. With `-Wspecdiffs` it reports the usual warning about the spec being narrower than the success typing. However, there's no mention of the actual return value and spec return type mismatch.

ETC reports a unification failure:

```
unify failed with types integer :=: boolean
```

Gradualizer does not report any errors.

## Working on Gradualizer

<!-- Learn more at https://mermaid-js.github.io/mermaid -->

```mermaid
graph TD;
  A("Run Gradualizer on some code")-->B{Errors reported?};
  B -- yes --> I
  I(Verify the code with review and/or tests) --> C{Errors actually present?};
  B -- no  --> F{Errors should be reported?};
  F -- yes - we've found a false-negative --> E;
  F -- no  --> G(Good job writing bug-free code!);
  C -- yes --> D(Fix your bugs!);
  C -- no - we've found a false-positive --> E(Send a PR with a test/known_problems case!);
  E --> H(Ideally, send a PR with a fix!);
```
